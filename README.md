
# ViT-LSTM/GRU Image Captioning Project

This project focuses on generating image captions using a combination of Vision Transformers (ViT) for image embeddings and LSTM/GRU models for sequence generation. The aim is to create descriptive captions for images using advanced deep learning techniques.
## Model Link : https://drive.google.com/drive/folders/1mZvcKd-C9rf3wPUAaWMKfvFTLgTha5IK?usp=sharing
## Datasets

The project supports the following datasets:

* **Flickr_30K**

Ensure you have downloaded and prepared these datasets in the appropriate format. Some images should be set aside for testing purposes.

## Project Milestones

To complete the project by October 30, we have set the following milestones:

1. **Data Preparation and Model Setup (Due: October 10)**
   - Download and preprocess datasets
   - Set up ViT model for image embedding generation
   - Implement basic LSTM/GRU architecture

2. **Model Training and Initial Evaluation (Due: October 20)**
   - Train the LSTM/GRU model on prepared data
   - Implement BLEU score evaluation
   - Conduct initial performance assessment

3. **Final Evaluation and Comparison (Due: October 30)**
   - Implement semantic distance evaluation
   - Compare results with LLM-generated captions
   - Prepare final report and documentation

## Team Responsibilities

The work is split among three team members as follows:

1. **Team Member A: **
   - Responsibilities:
     - Dataset download, preparation, and management
     - Implementation of ViT for image embedding generation
     - Data pipeline optimization

2. **Team Member B: **
   - Responsibilities:
     
3. **Team Member C: Ramshankar Bhuvaneswaran**
   - Responsibilities:
      - Adding Attention Layer
      - Implementation of Teacher Force Model

## Prerequisites

* Python 3.7+
* PyTorch
* Transformers
* TorchVision
* NumPy
* NLTK
* Matplotlib
